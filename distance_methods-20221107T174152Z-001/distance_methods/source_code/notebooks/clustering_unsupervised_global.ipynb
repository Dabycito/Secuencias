{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\0\\documents\\github\\secuencias\\venv\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\0\\documents\\github\\secuencias\\venv\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\0\\documents\\github\\secuencias\\venv\\lib\\site-packages (from scikit-learn) (1.23.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\0\\documents\\github\\secuencias\\venv\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\0\\documents\\github\\secuencias\\venv\\lib\\site-packages (from scikit-learn) (1.9.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\0\\Documents\\GitHub\\Secuencias\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, DBSCAN, MeanShift, MiniBatchKMeans, Birch, AffinityPropagation, AgglomerativeClustering\n",
    "from sklearn import metrics\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_performance_clustering(data, labels):\n",
    "    siluetas = metrics.silhouette_score(data, labels, metric='euclidean')\n",
    "    calinski = metrics.calinski_harabasz_score(data, labels)\n",
    "    davies = metrics.davies_bouldin_score(data, labels)\n",
    "\n",
    "    return siluetas, calinski, davies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    0 : \"absorption\",\n",
    "    1 : \"enantioselectivity\",\n",
    "    2 : \"localization\",\n",
    "    3 : \"T50\"\n",
    "}\n",
    "method = {\n",
    "    0:\"FFT\",\n",
    "    1:\"NLP\",\n",
    "    2:\"Properties\"\n",
    "}\n",
    "bioembedding = {\n",
    "    0:\"bepler\",\n",
    "    1:\"esm\",\n",
    "    2:\"fasttext\",\n",
    "    3:\"plus_rnn\",\n",
    "    4:\"prottrans\"\n",
    "}\n",
    "distances = {\n",
    "    1 : \"Euclidean\",\n",
    "    2 : \"Braycurtis\",\n",
    "    3 : \"Canberra\",\n",
    "    4 : \"Chebyshev\",\n",
    "    5 : \"Cityblock\",\n",
    "    6 : \"Correlation\",\n",
    "    7 : \"Cosine\",\n",
    "    8 : \"Minkowski\",\n",
    "    9 : \"Hamming\"\n",
    "}\n",
    "\n",
    "resultados = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for a in range(0,4):\n",
    "    for b in range(0,3):\n",
    "        if b == 1:\n",
    "            for c in range(0,5):\n",
    "                df_data = pd.read_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/\"+bioembedding[c]+\"-\"+dataset[a]+\".csv\")\n",
    "                ignore_columns = pd.DataFrame()\n",
    "                ignore_columns['id'] = df_data['id']\n",
    "                ignore_columns['target'] = df_data['target']\n",
    "\n",
    "                df_data = df_data.drop(columns=['id', 'target'])\n",
    "\n",
    "                '''------------KMEANS-----------------------------------------------------------'''\n",
    "\n",
    "                matrix_result = []\n",
    "                for k in range(2, 30):\n",
    "                    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "                    kmeans.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, kmeans.labels_)\n",
    "                    row = [\"k-means-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/results_kmeans.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                kmeans = KMeans(n_clusters=(int(strategies[0][8])), random_state=0)\n",
    "                kmeans.fit(df_data)\n",
    "                ignore_columns['labels'] = kmeans.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/unsupervised_clustering_sequences_kmeans.csv\")\n",
    "\n",
    "                '''------------BIRCH-----------------------------------------------------------'''\n",
    "\n",
    "                for k in range(2, 30):\n",
    "                    birch = Birch(n_clusters=k, threshold=0.1)\n",
    "                    birch.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, birch.labels_)\n",
    "                    row = [\"birch-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/results_birch.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                birch =Birch(n_clusters=(int(strategies[0][6])), threshold=0.1)\n",
    "                birch.fit(df_data)\n",
    "                ignore_columns['labels'] = birch.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/unsupervised_clustering_sequences_birch.csv\")\n",
    "\n",
    "                '''------------AGLOMERATIVE-----------------------------------------------------'''\n",
    "\n",
    "                matrix_result = []\n",
    "                for k in range(2, 30):\n",
    "                    aglomerative = AgglomerativeClustering(n_clusters=k)\n",
    "                    aglomerative.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, aglomerative.labels_)\n",
    "                    row = [\"aglomerative-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/results_aglomerative.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                aglomerative = AgglomerativeClustering(n_clusters=(int(strategies[0][13])))\n",
    "                aglomerative.fit(df_data)\n",
    "                ignore_columns['labels'] = aglomerative.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/unsupervised_clustering_sequences_aglomerative.csv\")\n",
    "        if b == 0:\n",
    "            for c in range (0,8):\n",
    "                df_data = pd.read_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+c+\"/fft-Group_\"+c+\"-\"+dataset[a]+\".csv\")\n",
    "                ignore_columns = pd.DataFrame()\n",
    "                ignore_columns['id'] = df_data['id']\n",
    "                ignore_columns['target'] = df_data['target']\n",
    "\n",
    "                df_data = df_data.drop(columns=['id', 'target'])\n",
    "\n",
    "                '''------------KMEANS-----------------------------------------------------------'''\n",
    "\n",
    "                matrix_result = []\n",
    "                for k in range(2, 30):\n",
    "                    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "                    kmeans.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, kmeans.labels_)\n",
    "                    row = [\"k-means-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+c+\"/results_kmeans.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/Group\"+c+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                kmeans = KMeans(n_clusters=(int(strategies[0][8])), random_state=0)\n",
    "                kmeans.fit(df_data)\n",
    "                ignore_columns['labels'] = kmeans.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+c+\"/unsupervised_clustering_sequences_kmeans.csv\")\n",
    "\n",
    "                '''------------BIRCH-----------------------------------------------------------'''\n",
    "\n",
    "                for k in range(2, 30):\n",
    "                    birch = Birch(n_clusters=k, threshold=0.1)\n",
    "                    birch.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, birch.labels_)\n",
    "                    row = [\"birch-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+c+\"/results_birch.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/Group\"+c+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                birch =Birch(n_clusters=(int(strategies[0][6])), threshold=0.1)\n",
    "                birch.fit(df_data)\n",
    "                ignore_columns['labels'] = birch.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+c+\"/unsupervised_clustering_sequences_birch.csv\")\n",
    "\n",
    "                '''------------AGLOMERATIVE-----------------------------------------------------'''\n",
    "\n",
    "                matrix_result = []\n",
    "                for k in range(2, 30):\n",
    "                    aglomerative = AgglomerativeClustering(n_clusters=k)\n",
    "                    aglomerative.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, aglomerative.labels_)\n",
    "                    row = [\"aglomerative-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+c+\"/results_aglomerative.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/Group\"+c+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                aglomerative = AgglomerativeClustering(n_clusters=(int(strategies[0][13])))\n",
    "                aglomerative.fit(df_data)\n",
    "                ignore_columns['labels'] = aglomerative.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+c+\"/unsupervised_clustering_sequences_aglomerative.csv\")\n",
    "        if b == 2:\n",
    "            for c in range(0,8):\n",
    "                df_data = pd.read_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+c+\"/physicochemical-Group_\"+c+\"-\"+dataset[a]+\".csv\")\n",
    "                ignore_columns = pd.DataFrame()\n",
    "                ignore_columns['id'] = df_data['id']\n",
    "                ignore_columns['target'] = df_data['target']\n",
    "\n",
    "                df_data = df_data.drop(columns=['id', 'target'])\n",
    "\n",
    "                '''------------KMEANS-----------------------------------------------------------'''\n",
    "\n",
    "                matrix_result = []\n",
    "                for k in range(2, 30):\n",
    "                    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "                    kmeans.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, kmeans.labels_)\n",
    "                    row = [\"k-means-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+c+\"/results_kmeans.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/Group\"+c+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                kmeans = KMeans(n_clusters=(int(strategies[0][8])), random_state=0)\n",
    "                kmeans.fit(df_data)\n",
    "                ignore_columns['labels'] = kmeans.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+c+\"/unsupervised_clustering_sequences_kmeans.csv\")\n",
    "\n",
    "                '''------------BIRCH-----------------------------------------------------------'''\n",
    "\n",
    "                for k in range(2, 30):\n",
    "                    birch = Birch(n_clusters=k, threshold=0.1)\n",
    "                    birch.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, birch.labels_)\n",
    "                    row = [\"birch-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+c+\"/results_birch.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/Group\"+c+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                birch =Birch(n_clusters=(int(strategies[0][6])), threshold=0.1)\n",
    "                birch.fit(df_data)\n",
    "                ignore_columns['labels'] = birch.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+c+\"/unsupervised_clustering_sequences_birch.csv\")\n",
    "\n",
    "                '''------------AGLOMERATIVE-----------------------------------------------------'''\n",
    "\n",
    "                matrix_result = []\n",
    "                for k in range(2, 30):\n",
    "                    aglomerative = AgglomerativeClustering(n_clusters=k)\n",
    "                    aglomerative.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, aglomerative.labels_)\n",
    "                    row = [\"aglomerative-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+c+\"/results_aglomerative.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/Group\"+c+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                aglomerative = AgglomerativeClustering(n_clusters=(int(strategies[0][13])))\n",
    "                aglomerative.fit(df_data)\n",
    "                ignore_columns['labels'] = aglomerative.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+c+\"/unsupervised_clustering_sequences_aglomerative.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resultados"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}