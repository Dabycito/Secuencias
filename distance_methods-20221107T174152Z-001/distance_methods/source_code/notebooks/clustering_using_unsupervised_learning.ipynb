{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\r\n",
      "  Downloading scikit_learn-1.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\r\n",
      "\u001B[2K     \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m30.5/30.5 MB\u001B[0m \u001B[31m522.1 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0mm eta \u001B[36m0:00:01\u001B[0m[36m0:00:02\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: joblib>=1.0.0 in /home/daniel/.local/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/daniel/.local/lib/python3.10/site-packages (from scikit-learn) (1.23.4)\r\n",
      "Collecting threadpoolctl>=2.0.0\r\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/daniel/.local/lib/python3.10/site-packages (from scikit-learn) (1.9.3)\r\n",
      "Installing collected packages: threadpoolctl, scikit-learn\r\n",
      "Successfully installed scikit-learn-1.1.3 threadpoolctl-3.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, DBSCAN, MeanShift, MiniBatchKMeans, Birch, AffinityPropagation, AgglomerativeClustering\n",
    "from sklearn import metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                 id    target     p_0     p_1     p_2     p_3     p_4     p_5  \\\n0    sequence_51016 -4.626936  0.0136  0.0132 -0.0103  0.0071  0.0485  0.0117   \n1    sequence_51170 -5.599110  0.0222  0.0125 -0.0099  0.0118  0.0571  0.0126   \n2    sequence_32130 -5.715788 -0.0053  0.0133 -0.0090  0.0103  0.0602 -0.0045   \n3    sequence_51136 -5.335352  0.0145  0.0076 -0.0150  0.0085  0.0512  0.0005   \n4    sequence_51191 -4.187052  0.0206  0.0147 -0.0090  0.0124  0.0483  0.0132   \n..              ...       ...     ...     ...     ...     ...     ...     ...   \n243  sequence_50986 -6.800648  0.0135  0.0074 -0.0092  0.0082  0.0426  0.0157   \n244  sequence_51042 -4.418679  0.0031  0.0182 -0.0111 -0.0005  0.0602  0.0073   \n245  sequence_51024 -4.606671  0.0041  0.0167 -0.0160  0.0003  0.0554  0.0055   \n246  sequence_51037 -4.148785  0.0131  0.0149 -0.0099  0.0043  0.0621  0.0116   \n247  sequence_51146 -3.958357  0.0216  0.0132 -0.0082  0.0135  0.0462  0.0153   \n\n        p_6     p_7  ...  p_1014  p_1015  p_1016  p_1017  p_1018  p_1019  \\\n0   -0.0241  0.0175  ...  0.0033 -0.0297 -0.0106  0.0147  0.0638 -0.0409   \n1   -0.0331  0.0140  ...  0.0107 -0.0482 -0.0198  0.0136  0.0563 -0.0370   \n2   -0.0350  0.0110  ...  0.0077 -0.0451 -0.0244  0.0232  0.0684 -0.0376   \n3   -0.0305  0.0158  ...  0.0118 -0.0581 -0.0134  0.0119  0.0677 -0.0320   \n4   -0.0295  0.0199  ...  0.0059 -0.0386 -0.0125  0.0113  0.0637 -0.0357   \n..      ...     ...  ...     ...     ...     ...     ...     ...     ...   \n243 -0.0275  0.0148  ...  0.0054 -0.0285 -0.0139  0.0135  0.0632 -0.0416   \n244 -0.0235  0.0139  ...  0.0067 -0.0356 -0.0209  0.0129  0.0631 -0.0425   \n245 -0.0197  0.0159  ...  0.0069 -0.0397 -0.0135  0.0144  0.0612 -0.0419   \n246 -0.0283  0.0093  ...  0.0028 -0.0319 -0.0204  0.0114  0.0663 -0.0398   \n247 -0.0292  0.0200  ...  0.0057 -0.0398 -0.0159  0.0110  0.0647 -0.0361   \n\n     p_1020  p_1021  p_1022  p_1023  \n0    0.0177  0.0065 -0.0526 -0.0009  \n1    0.0166  0.0121 -0.0457  0.0085  \n2    0.0221  0.0055 -0.0592  0.0053  \n3    0.0213  0.0075 -0.0537  0.0105  \n4    0.0147  0.0046 -0.0523  0.0057  \n..      ...     ...     ...     ...  \n243  0.0155  0.0065 -0.0538  0.0018  \n244  0.0119  0.0073 -0.0524  0.0055  \n245  0.0183  0.0054 -0.0547  0.0047  \n246  0.0179  0.0103 -0.0500  0.0016  \n247  0.0128  0.0084 -0.0522  0.0060  \n\n[248 rows x 1026 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n      <th>p_0</th>\n      <th>p_1</th>\n      <th>p_2</th>\n      <th>p_3</th>\n      <th>p_4</th>\n      <th>p_5</th>\n      <th>p_6</th>\n      <th>p_7</th>\n      <th>...</th>\n      <th>p_1014</th>\n      <th>p_1015</th>\n      <th>p_1016</th>\n      <th>p_1017</th>\n      <th>p_1018</th>\n      <th>p_1019</th>\n      <th>p_1020</th>\n      <th>p_1021</th>\n      <th>p_1022</th>\n      <th>p_1023</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sequence_51016</td>\n      <td>-4.626936</td>\n      <td>0.0136</td>\n      <td>0.0132</td>\n      <td>-0.0103</td>\n      <td>0.0071</td>\n      <td>0.0485</td>\n      <td>0.0117</td>\n      <td>-0.0241</td>\n      <td>0.0175</td>\n      <td>...</td>\n      <td>0.0033</td>\n      <td>-0.0297</td>\n      <td>-0.0106</td>\n      <td>0.0147</td>\n      <td>0.0638</td>\n      <td>-0.0409</td>\n      <td>0.0177</td>\n      <td>0.0065</td>\n      <td>-0.0526</td>\n      <td>-0.0009</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sequence_51170</td>\n      <td>-5.599110</td>\n      <td>0.0222</td>\n      <td>0.0125</td>\n      <td>-0.0099</td>\n      <td>0.0118</td>\n      <td>0.0571</td>\n      <td>0.0126</td>\n      <td>-0.0331</td>\n      <td>0.0140</td>\n      <td>...</td>\n      <td>0.0107</td>\n      <td>-0.0482</td>\n      <td>-0.0198</td>\n      <td>0.0136</td>\n      <td>0.0563</td>\n      <td>-0.0370</td>\n      <td>0.0166</td>\n      <td>0.0121</td>\n      <td>-0.0457</td>\n      <td>0.0085</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sequence_32130</td>\n      <td>-5.715788</td>\n      <td>-0.0053</td>\n      <td>0.0133</td>\n      <td>-0.0090</td>\n      <td>0.0103</td>\n      <td>0.0602</td>\n      <td>-0.0045</td>\n      <td>-0.0350</td>\n      <td>0.0110</td>\n      <td>...</td>\n      <td>0.0077</td>\n      <td>-0.0451</td>\n      <td>-0.0244</td>\n      <td>0.0232</td>\n      <td>0.0684</td>\n      <td>-0.0376</td>\n      <td>0.0221</td>\n      <td>0.0055</td>\n      <td>-0.0592</td>\n      <td>0.0053</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sequence_51136</td>\n      <td>-5.335352</td>\n      <td>0.0145</td>\n      <td>0.0076</td>\n      <td>-0.0150</td>\n      <td>0.0085</td>\n      <td>0.0512</td>\n      <td>0.0005</td>\n      <td>-0.0305</td>\n      <td>0.0158</td>\n      <td>...</td>\n      <td>0.0118</td>\n      <td>-0.0581</td>\n      <td>-0.0134</td>\n      <td>0.0119</td>\n      <td>0.0677</td>\n      <td>-0.0320</td>\n      <td>0.0213</td>\n      <td>0.0075</td>\n      <td>-0.0537</td>\n      <td>0.0105</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sequence_51191</td>\n      <td>-4.187052</td>\n      <td>0.0206</td>\n      <td>0.0147</td>\n      <td>-0.0090</td>\n      <td>0.0124</td>\n      <td>0.0483</td>\n      <td>0.0132</td>\n      <td>-0.0295</td>\n      <td>0.0199</td>\n      <td>...</td>\n      <td>0.0059</td>\n      <td>-0.0386</td>\n      <td>-0.0125</td>\n      <td>0.0113</td>\n      <td>0.0637</td>\n      <td>-0.0357</td>\n      <td>0.0147</td>\n      <td>0.0046</td>\n      <td>-0.0523</td>\n      <td>0.0057</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>243</th>\n      <td>sequence_50986</td>\n      <td>-6.800648</td>\n      <td>0.0135</td>\n      <td>0.0074</td>\n      <td>-0.0092</td>\n      <td>0.0082</td>\n      <td>0.0426</td>\n      <td>0.0157</td>\n      <td>-0.0275</td>\n      <td>0.0148</td>\n      <td>...</td>\n      <td>0.0054</td>\n      <td>-0.0285</td>\n      <td>-0.0139</td>\n      <td>0.0135</td>\n      <td>0.0632</td>\n      <td>-0.0416</td>\n      <td>0.0155</td>\n      <td>0.0065</td>\n      <td>-0.0538</td>\n      <td>0.0018</td>\n    </tr>\n    <tr>\n      <th>244</th>\n      <td>sequence_51042</td>\n      <td>-4.418679</td>\n      <td>0.0031</td>\n      <td>0.0182</td>\n      <td>-0.0111</td>\n      <td>-0.0005</td>\n      <td>0.0602</td>\n      <td>0.0073</td>\n      <td>-0.0235</td>\n      <td>0.0139</td>\n      <td>...</td>\n      <td>0.0067</td>\n      <td>-0.0356</td>\n      <td>-0.0209</td>\n      <td>0.0129</td>\n      <td>0.0631</td>\n      <td>-0.0425</td>\n      <td>0.0119</td>\n      <td>0.0073</td>\n      <td>-0.0524</td>\n      <td>0.0055</td>\n    </tr>\n    <tr>\n      <th>245</th>\n      <td>sequence_51024</td>\n      <td>-4.606671</td>\n      <td>0.0041</td>\n      <td>0.0167</td>\n      <td>-0.0160</td>\n      <td>0.0003</td>\n      <td>0.0554</td>\n      <td>0.0055</td>\n      <td>-0.0197</td>\n      <td>0.0159</td>\n      <td>...</td>\n      <td>0.0069</td>\n      <td>-0.0397</td>\n      <td>-0.0135</td>\n      <td>0.0144</td>\n      <td>0.0612</td>\n      <td>-0.0419</td>\n      <td>0.0183</td>\n      <td>0.0054</td>\n      <td>-0.0547</td>\n      <td>0.0047</td>\n    </tr>\n    <tr>\n      <th>246</th>\n      <td>sequence_51037</td>\n      <td>-4.148785</td>\n      <td>0.0131</td>\n      <td>0.0149</td>\n      <td>-0.0099</td>\n      <td>0.0043</td>\n      <td>0.0621</td>\n      <td>0.0116</td>\n      <td>-0.0283</td>\n      <td>0.0093</td>\n      <td>...</td>\n      <td>0.0028</td>\n      <td>-0.0319</td>\n      <td>-0.0204</td>\n      <td>0.0114</td>\n      <td>0.0663</td>\n      <td>-0.0398</td>\n      <td>0.0179</td>\n      <td>0.0103</td>\n      <td>-0.0500</td>\n      <td>0.0016</td>\n    </tr>\n    <tr>\n      <th>247</th>\n      <td>sequence_51146</td>\n      <td>-3.958357</td>\n      <td>0.0216</td>\n      <td>0.0132</td>\n      <td>-0.0082</td>\n      <td>0.0135</td>\n      <td>0.0462</td>\n      <td>0.0153</td>\n      <td>-0.0292</td>\n      <td>0.0200</td>\n      <td>...</td>\n      <td>0.0057</td>\n      <td>-0.0398</td>\n      <td>-0.0159</td>\n      <td>0.0110</td>\n      <td>0.0647</td>\n      <td>-0.0361</td>\n      <td>0.0128</td>\n      <td>0.0084</td>\n      <td>-0.0522</td>\n      <td>0.0060</td>\n    </tr>\n  </tbody>\n</table>\n<p>248 rows × 1026 columns</p>\n</div>"
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv(\"../../results_demo/localization/NLP/prottrans/prottrans_bert_bfd-localization.csv\")\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_clustering(data, labels):\n",
    "    siluetas = metrics.silhouette_score(data, labels, metric='euclidean')\n",
    "    calinski = metrics.calinski_harabasz_score(data, labels)\n",
    "    davies = metrics.davies_bouldin_score(data, labels)\n",
    "\n",
    "    return siluetas, calinski, davies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignoramos y removemos las columnas que no ocuparemos para el clustering\n",
    "ignore_columns = pd.DataFrame()\n",
    "ignore_columns['id'] = df_data['id']\n",
    "ignore_columns['target'] = df_data['target']\n",
    "\n",
    "df_data = df_data.drop(columns=['id', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploramos KNN\n",
    "matrix_result = []\n",
    "for k in range(2, 30):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(df_data)\n",
    "    siluetas, calinski, davies = get_performance_clustering(df_data, kmeans.labels_)\n",
    "    row = [\"k-means-{}\".format(k), siluetas, calinski, davies]\n",
    "    matrix_result.append(row)\n",
    "\n",
    "df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['k-means-2'], dtype=object)"
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seleccionamos el mejor\n",
    "import numpy as np\n",
    "\n",
    "highest_siluetas = np.max(df_explore['siluetas'])\n",
    "highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "# filtramos\n",
    "df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "strategies = df_concat['strategy'].unique()\n",
    "strategies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en este caso salio el mejor k-means=2\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "kmeans.fit(df_data)\n",
    "ignore_columns['labels'] = kmeans.labels_\n",
    "\n",
    "ignore_columns.to_csv(\"../../results_demo/localization/NLP/prottrans/unsupervised_clustering_sequences.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('deep_learning_exploring')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40e745f296283c3457427b1d4d0e6f488c7d44751c90dcd83420fd4dcb83c0cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
